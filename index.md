---
layout: default
---

# Hello! 

Hi, welcome to my website! 
I'm a research engineer at Google. I'm currently interested in the following topics:

- Interpretability
  - Feature attribution methods
  - (Latent) Rationales
  - Using inherently interpretable models for NLP
  - Evaluating explanations (e.g., are they faithful/plausible/useful?)
- Machine Learning for NLP (e.g., deep latent variable models)
- Neural Machine Translation (e.g., with linguistic priors)

Previously I was a PhD student at [ILLC](https://www.illc.uva.nl/), [University of Amsterdam](https://www.uva.nl/), where I was advised by [Wilker Aziz](https://wilkeraziz.github.io/), [Ivan Titov](http://ivan-titov.org/) and [Khalil Sima'an](https://staff.fnwi.uva.nl/k.simaan/index.html). 

# Publications

You can find my [publications](https://scholar.google.com/citations?user=VG_wuYkAAAAJ&hl=en) on Google Scholar.

# Talks

- ACL 2019. [Interpretable Neural Predictions with Differentiable Binary Variables](https://docs.google.com/presentation/d/1_32rmjbd4tbYfQOcsNJm9itUg8Rb6OlzGuq6VjM_Y88/edit?usp=sharing) (Google Slides)
- EMNLP 2017. [Graph Convolutional Encoders for Syntax-Aware Neural Machine Translation](https://docs.google.com/presentation/d/1-9amED4gkN3gNph_AXY7fj3n6Z_77GlRRyt618uqElk/edit?usp=sharing) (Google Slides)

# CV

* 2006-2009, BSc in AI, [Utrecht University](https://www.uu.nl/).
* 2009-2012, MSc in AI, [University of Amsterdam](https://www.uva.nl/).
* 2015-2020. PhD, [ILLC](https://www.illc.uva.nl/), [University of Amsterdam](https://www.uva.nl/). *Defense planned for October 2020.*
* 2019-Now, Research Engineer, [Google](https://ai.google/).

# Reviewing

I reviewed for the following conferences and workshops:

* ACL (2019, 2020)
* EMNLP (2018, 2019, 2020)
* CoNNL (2018, 2019)
* ICLR (2020)
* MT Summit (2019)
* WMT (2018, 2019)
* Analyzing and interpreting neural networks for NLP (BlackboxNLP, 2019)
* Debugging Machine Learning Models (Debug ML, ICLR Workshop, 2019)
* Workshop on Neural Generation and Translation (WNGT, 2018, 2019, 2020)
* Workshop on Representation Learning for NLP (RepL4NLP, 2020)
* Workshop on Structured Prediction for NLP (SPNLP, 2019)

# Supervision

During my PhD I supervised the following students:

* Joost Baptist (MSc Thesis)
* Laura Ruis (Honours Project)

# Projects

* [Differentiable Binary Variables](https://github.com/bastings/interpretable_predictions) contains the HardKuma distribution that allows (hybrid) binary samples (with *true* zeros and ones) that allow gradients to pass through.
* [Joey NMT](https://github.com/joeynmt/joeynmt) is an easy-to-use, educational, and benchmarked NMT toolkit for novices that I developed with Julia Kreutzer. 
* [FREVAL](https://github.com/bastings/freval) is an all-fragments parser evaluation metric that I developed with Khalil Sima'an.


# Contact

* You can find me on Twitter: [@bastings_nlp](https://twitter.com/bastings_nlp).
* My code is on Github: [github.com/bastings](https://github.com/bastings).
