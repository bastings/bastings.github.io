---
layout: default
---

# Jasmijn Bastings

## Hello

Hi, welcome to my website! My name is Jasmijn (she/her), and I'm a Research Scientist at Google. Currently I'm interested in the following topics, especially in the context of Natural Language Processing:

- Interpretability / Explainability / Explainable AI (XAI)
- Efficiency
- Trustworthy ML
- Machine Learning

I received my PhD from [ILLC](https://www.illc.uva.nl/), [University of Amsterdam](https://www.uva.nl/), where I was advised by [Wilker Aziz](https://wilkeraziz.github.io/), [Ivan Titov](http://ivan-titov.org/) and [Khalil Sima'an](https://staff.fnwi.uva.nl/k.simaan/index.html). 

## Publications

### Recent publications

- ["Will You Find These Shortcuts?" A Protocol for Evaluating the Faithfulness of Input Salience Methods for Text Classification](https://arxiv.org/abs/2111.07367). **Jasmijn Bastings**, Sebastian Ebert, Polina Zablotskaia, Anders Sandholm, Katja Filippova. EMNLP 2022. [[blog](https://ai.googleblog.com/2022/12/will-you-find-these-shortcuts.html)]
- [Training Text-to-Text Transformers with Privacy Guarantees](https://aclanthology.org/2022.findings-acl.171/). Natalia Ponomareva, **Jasmijn Bastings**, Sergei Vassilvitskii. Findings of ACL 2022.
- [The MultiBERTs: BERT Reproductions for Robustness Analysis](https://openreview.net/forum?id=K0E_F0gFDgA). Thibault Sellam, Steve Yadlowsky, Jason Wei, Naomi Saphra, Alexander D'Amour, Tal Linzen, **Jasmijn Bastings**, Iulia Turc, Jacob Eisenstein, Dipanjan Das, Ian Tenney, Ellie Pavlick. ICLR 2022.
- [Diagnosing ai explanation methods with folk concepts of behavior](https://arxiv.org/abs/2201.11239). Alon Jacovi, **Jasmijn Bastings**, Sebastian Gehrmann, Yoav Goldberg, Katja Filippova. 2021.
- [Simple Recurrence Improves Masked Language Models](https://arxiv.org/abs/2205.11588). Tao Lei, Ran Tian, **Jasmijn Bastings**, Ankur P Parikh.

### Highlighted publications

- [The elephant in the interpretability room: Why use attention as explanation when we have saliency methods?](https://aclanthology.org/2020.blackboxnlp-1.14/). **Jasmijn Bastings**, Katja Filippova. BlackboxBLP 2020.
- [Interpretable neural predictions with differentiable binary variables](https://aclanthology.org/P19-1284/). **Jasmijn Bastings**, Wilker Aziz, Ivan Titov. ACL 2019.
- [Joey NMT: A Minimalist NMT Toolkit for Novices](https://aclanthology.org/D19-3019/). Julia Kreutzer, **Jasmijn Bastings**, Stefan Riezler. EMNLP 2019. [[code](https://github.com/joeynmt/joeynmt)]
- [Graph convolutional encoders for syntax-aware neural machine translation](https://aclanthology.org/D17-1209/) **Jasmijn Bastings**, Ivan Titov, Wilker Aziz, Diego Marcheggiani, Khalil Sima'an. EMNLP 2017.


You can a full list of my publications at [publications](https://scholar.google.com/citations?user=VG_wuYkAAAAJ&hl=en) on Google Scholar.


### Blog posts

- [The Annotated Encoder-Decoder](https://bastings.github.io/annotated_encoder_decoder/). Explains implementing RNN-based NMT models in PyTorch.


## Talks

- EMNLP 2020 Blackbox NLP. [The Elephant in the Interpretability Room. (PDF)](https://github.com/bastings/bastings.github.io/raw/master/elephant_slides.pdf)
- ACL 2019. [Interpretable Neural Predictions with Differentiable Binary Variables](https://docs.google.com/presentation/d/1_32rmjbd4tbYfQOcsNJm9itUg8Rb6OlzGuq6VjM_Y88/edit?usp=sharing) (Google Slides)
- EMNLP 2017. [Graph Convolutional Encoders for Syntax-Aware Neural Machine Translation](https://docs.google.com/presentation/d/1-9amED4gkN3gNph_AXY7fj3n6Z_77GlRRyt618uqElk/edit?usp=sharing) (Google Slides)

## CV

* 2019-Now, Research Scientist, [Google](https://ai.google/). Berlin & Amsterdam.
* 2015-2020. PhD in AI, [ILLC](https://www.illc.uva.nl/), [University of Amsterdam](https://www.uva.nl/). Defended 8 October 2020.*
* 2009-2012, MSc in AI, [University of Amsterdam](https://www.uva.nl/).
* 2006-2009, BSc in AI, [Utrecht University](https://www.uu.nl/).

## Reviewing / Area Chair / Committees

I am a co-organizer of:

* [Blackbox NLP 2022](https://blackboxnlp.github.io/) (co-located with EMNLP 2022)
* Blackbox NLP 2021 (co-located with EMNLP 2021)

I was area chair (AC) / action editor (AE) for the following conferences:

* ACL (2021, 2022, 2023) (Interpretability and Analysis of Models for NLP)
* EMNLP (2021, 2022) (Interpretability and Analysis of Models for NLP)
* ACL rolling review (2021-2022)
* EACL (2021) (Machine Learning for NLP)
* NAACL (2021) (Interpretability and Analysis of Models for NLP)

I reviewed for the following conferences and workshops:

* ACL (2019, 2020)
* EMNLP (2018, 2019, 2020)
* CoNNL (2018, 2019)
* ICLR (2020)
* MT Summit (2019)
* WMT (2018, 2019)
* Analyzing and interpreting neural networks for NLP (BlackboxNLP, 2019, 2020)
* Debugging Machine Learning Models (Debug ML, ICLR Workshop, 2019)
* Workshop on Neural Generation and Translation (WNGT, 2018, 2019, 2020)
* Workshop on Representation Learning for NLP (RepL4NLP, 2020)
* Workshop on Structured Prediction for NLP (SPNLP, 2019)

## Code

* [Interpretable Neural Predictions with Differentiable Binary Variables](https://github.com/bastings/interpretable_predictions) contains the HardKuma distribution that allows (hybrid) binary samples (with *true* zeros and ones) that allow gradients to pass through.
* [Joey NMT](https://github.com/joeynmt/joeynmt) is an easy-to-use, educational, and benchmarked NMT toolkit for novices that I developed with Julia Kreutzer. 
* [FREVAL](https://github.com/bastings/freval) is an all-fragments parser evaluation metric that I developed with Khalil Sima'an.


# Contact

* <a rel="me" href="https://sigmoid.social/@jasmijn">Mastodon</a>
* You can find me on Twitter: [@BastingsJasmijn](https://twitter.com/BastingsJasmijn).
* My code is on Github: [github.com/bastings](https://github.com/bastings).

<div itemscope itemtype="https://schema.org/Person"><a itemprop="sameAs" content="https://orcid.org/0000-0002-5445-4417" href="https://orcid.org/0000-0002-5445-4417" target="orcid.widget" rel="me noopener noreferrer" style="vertical-align:top;"><img src="https://orcid.org/sites/default/files/images/orcid_16x16.png" style="width:1em;margin-right:.5em;" alt="ORCID iD icon">https://orcid.org/0000-0002-5445-4417</a></div>
