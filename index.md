---
layout: default
---

# Hello! 

Hi, welcome to my website! My name is Jasmijn (she/her), and I'm a research engineer at Google. Currently I'm interested in the following topics within Natural Language Processing and Machine Learning:

- Interpretability
- Fairness
- Robustness

I received my PhD from [ILLC](https://www.illc.uva.nl/), [University of Amsterdam](https://www.uva.nl/), where I was advised by [Wilker Aziz](https://wilkeraziz.github.io/), [Ivan Titov](http://ivan-titov.org/) and [Khalil Sima'an](https://staff.fnwi.uva.nl/k.simaan/index.html). 

# Publications

You can find my [publications](https://scholar.google.com/citations?user=VG_wuYkAAAAJ&hl=en) on Google Scholar.

# Talks

- EMNLP 2020 Blackbox NLP. The Elephant in the Interpretability Room. (Google Slides)
- ACL 2019. [Interpretable Neural Predictions with Differentiable Binary Variables](https://docs.google.com/presentation/d/1_32rmjbd4tbYfQOcsNJm9itUg8Rb6OlzGuq6VjM_Y88/edit?usp=sharing) (Google Slides)
- EMNLP 2017. [Graph Convolutional Encoders for Syntax-Aware Neural Machine Translation](https://docs.google.com/presentation/d/1-9amED4gkN3gNph_AXY7fj3n6Z_77GlRRyt618uqElk/edit?usp=sharing) (Google Slides)

# Blog posts

* 2018. [The Annotated Encoder-Decoder](https://bastings.github.io/annotated_encoder_decoder/). Explains implementing RNN-based NMT models in PyTorch.

# CV

* 2006-2009, BSc in AI, [Utrecht University](https://www.uu.nl/).
* 2009-2012, MSc in AI, [University of Amsterdam](https://www.uva.nl/).
* 2015-2020. PhD in AI, [ILLC](https://www.illc.uva.nl/), [University of Amsterdam](https://www.uva.nl/). Defended 8 October 2020.*
* 2019-Now, Research Engineer, [Google](https://ai.google/).

# Reviewing / Area Chair

I was area chair (AC) for the following conferences:

* EACL 2021 (Machine Learning for NLP)
* NAACL 2021 (Interpretability and Analysis of Models for NLP)
* ACL 2021 (Interpretability and Analysis of Models for NLP)

I reviewed for the following conferences and workshops:

* ACL (2019, 2020)
* EMNLP (2018, 2019, 2020)
* CoNNL (2018, 2019)
* ICLR (2020)
* MT Summit (2019)
* WMT (2018, 2019)
* Analyzing and interpreting neural networks for NLP (BlackboxNLP, 2019, 2020)
* Debugging Machine Learning Models (Debug ML, ICLR Workshop, 2019)
* Workshop on Neural Generation and Translation (WNGT, 2018, 2019, 2020)
* Workshop on Representation Learning for NLP (RepL4NLP, 2020)
* Workshop on Structured Prediction for NLP (SPNLP, 2019)

# Supervision

During my PhD I supervised the following students:

* J. Baptist (MSc Thesis)
* Laura Ruis (Honours Project)

# Projects

* [Interpretable Neural Predictions with Differentiable Binary Variables](https://github.com/bastings/interpretable_predictions) contains the HardKuma distribution that allows (hybrid) binary samples (with *true* zeros and ones) that allow gradients to pass through.
* [Joey NMT](https://github.com/joeynmt/joeynmt) is an easy-to-use, educational, and benchmarked NMT toolkit for novices that I developed with Julia Kreutzer. 
* [FREVAL](https://github.com/bastings/freval) is an all-fragments parser evaluation metric that I developed with Khalil Sima'an.


# Contact

* You can find me on Twitter: [@BastingsJasmijn](https://twitter.com/BastingsJasmijn).
* My code is on Github: [github.com/bastings](https://github.com/bastings).
