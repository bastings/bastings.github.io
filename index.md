---
layout: default
---

# Jasmijn Bastings

## Hello

Hi, welcome to my website! My name is Jasmijn (she/they), and I'm a Senior Research Scientist at [Google DeepMind](https://www.deepmind.com/). 
I'd like to make machine learning (or "AI") work for **everyone**. To help get there I'm currently interested in the following topics:

- Interpretability, Explainable AI (XAI), explainability
- Bias, gender bias, gender-fair language, gender-fair language technology
- AI & Society
- Trustworthy ML, Trustworthy AI, trustworthiness

I received my PhD from [ILLC](https://www.illc.uva.nl/), [University of Amsterdam](https://www.uva.nl/), where I was advised by [Wilker Aziz](https://wilkeraziz.github.io/), [Ivan Titov](http://ivan-titov.org/) and [Khalil Sima'an](https://staff.fnwi.uva.nl/k.simaan/index.html). 

## News

- I won an [outstanding Area Chair award](https://2023.aclweb.org/program/best_reviewers/) at ACL 2023!
- June 2023: I will be part of the project "An Interdisciplinary Analysis of gender-based discrimination in Translation Technology", [funded by the Digital Sciences for Society program of Tilburg University](https://www.tilburguniversity.edu/current/news/more-news/tilburg-university-invests-digital-sciences-society), a collaboration with [Eva Vanmassenhove](https://www.tilburguniversity.edu/nl/medewerkers/e-o-j-vanmassenhove) (NLP/translation), Hanna Lukkari (Law), Seunghyun Song (Philosophy).
- I started a YouTube channel for BlackboxNLP. Check it out and subscibe here: [youtube.com/@blackboxnlp](http://www.youtube.com/@blackboxnlp).
- You can now find me on Mastodon: `@jasmijn@sigmoid.social` or [https://sigmoid.social/@jasmijn](https://sigmoid.social/@jasmijn).

## Publications

### Recent publications

- **New** [Dissecting Recall of Factual Associations in Auto-Regressive Language Models](https://arxiv.org/abs/2304.14767). Mor Geva, **Jasmijn Bastings**, Katja Filippova, Amir Globerson. Preprint.
- ["Will You Find These Shortcuts?" A Protocol for Evaluating the Faithfulness of Input Salience Methods for Text Classification](https://arxiv.org/abs/2111.07367). **Jasmijn Bastings**, Sebastian Ebert, Polina Zablotskaia, Anders Sandholm, Katja Filippova. EMNLP 2022. [[blog](https://ai.googleblog.com/2022/12/will-you-find-these-shortcuts.html)]
- [Diagnosing ai explanation methods with folk concepts of behavior](https://arxiv.org/abs/2201.11239). Alon Jacovi, **Jasmijn Bastings**, Sebastian Gehrmann, Yoav Goldberg, Katja Filippova. 2021.

See my full publication list on my [Google Scholar profile](https://scholar.google.com/citations?user=VG_wuYkAAAAJ&hl=en).

### Highlighted publications

- [The elephant in the interpretability room: Why use attention as explanation when we have saliency methods?](https://aclanthology.org/2020.blackboxnlp-1.14/). **Jasmijn Bastings**, Katja Filippova. BlackboxNLP 2020.
- [Interpretable neural predictions with differentiable binary variables](https://aclanthology.org/P19-1284/). **Jasmijn Bastings**, Wilker Aziz, Ivan Titov. ACL 2019.
- [Joey NMT: A Minimalist NMT Toolkit for Novices](https://aclanthology.org/D19-3019/). Julia Kreutzer, **Jasmijn Bastings**, Stefan Riezler. EMNLP 2019. [[code](https://github.com/joeynmt/joeynmt)]
- [Graph convolutional encoders for syntax-aware neural machine translation](https://aclanthology.org/D17-1209/) **Jasmijn Bastings**, Ivan Titov, Wilker Aziz, Diego Marcheggiani, Khalil Sima'an. EMNLP 2017.

You can find a full list of my publications on my [Google Scholar profile](https://scholar.google.com/citations?user=VG_wuYkAAAAJ&hl=en).

### Blog posts

- [The Annotated Encoder-Decoder](https://bastings.github.io/annotated_encoder_decoder/). Explains implementing RNN-based NMT models in PyTorch.

## Code

* [Interpretable Neural Predictions with Differentiable Binary Variables](https://github.com/bastings/interpretable_predictions) contains the HardKuma distribution that allows (hybrid) binary samples (with *true* zeros and ones) that allow gradients to pass through.
* [Joey NMT](https://github.com/joeynmt/joeynmt) is an easy-to-use, educational, and benchmarked NMT toolkit for novices that I developed with Julia Kreutzer and is currently maintained by Mayumi Ohta. 
* [FREVAL](https://github.com/bastings/freval) is an all-fragments parser evaluation metric that I developed with Khalil Sima'an.

## Talks

- EMNLP 2020 Blackbox NLP. [The Elephant in the Interpretability Room. (PDF)](https://github.com/bastings/bastings.github.io/raw/master/elephant_slides.pdf)
- ACL 2019. [Interpretable Neural Predictions with Differentiable Binary Variables](https://docs.google.com/presentation/d/1_32rmjbd4tbYfQOcsNJm9itUg8Rb6OlzGuq6VjM_Y88/edit?usp=sharing) (Google Slides)
- EMNLP 2017. [Graph Convolutional Encoders for Syntax-Aware Neural Machine Translation](https://docs.google.com/presentation/d/1-9amED4gkN3gNph_AXY7fj3n6Z_77GlRRyt618uqElk/edit?usp=sharing) (Google Slides)

## CV

* 2019-Now, Research Scientist, [Google](https://ai.google/). Berlin & Amsterdam.
* 2015-2020. PhD in AI, [ILLC](https://www.illc.uva.nl/), [University of Amsterdam](https://www.uva.nl/). Defended 8 October 2020.*
* 2009-2012, MSc in AI, [University of Amsterdam](https://www.uva.nl/).
* 2006-2009, BSc in AI, [Utrecht University](https://www.uu.nl/).

## Reviewing / Area Chair / Committees

I was a co-organizer of:

* [Blackbox NLP 2022](https://blackboxnlp.github.io/) (co-located with EMNLP 2022)
* Blackbox NLP 2021 (co-located with EMNLP 2021)

I was area chair (AC) / action editor (AE) for the following conferences:

* ACL (2021, 2022, 2023) (Interpretability and Analysis of Models for NLP)
* EMNLP (2021, 2022) (Interpretability and Analysis of Models for NLP)
* ACL rolling review (2021-2022)
* EACL (2021) (Machine Learning for NLP)
* NAACL (2021) (Interpretability and Analysis of Models for NLP)

I reviewed for the following conferences and workshops:

* ACL (2019, 2020)
* EMNLP (2018, 2019, 2020)
* CoNNL (2018, 2019)
* ICLR (2020)
* MT Summit (2019)
* WMT (2018, 2019)
* Analyzing and interpreting neural networks for NLP (BlackboxNLP, 2019, 2020)
* Debugging Machine Learning Models (Debug ML, ICLR Workshop, 2019)
* Workshop on Neural Generation and Translation (WNGT, 2018, 2019, 2020)
* Workshop on Representation Learning for NLP (RepL4NLP, 2020)
* Workshop on Structured Prediction for NLP (SPNLP, 2019)


# Contact

* <a rel="me" href="https://sigmoid.social/@jasmijn">Mastodon</a>
* You can find me on Twitter: [@jasmijnbastings](https://twitter.com/jasmijnbastings).
* My code is on Github: [github.com/bastings](https://github.com/bastings).

<div itemscope itemtype="https://schema.org/Person"><a itemprop="sameAs" content="https://orcid.org/0000-0002-5445-4417" href="https://orcid.org/0000-0002-5445-4417" target="orcid.widget" rel="me noopener noreferrer" style="vertical-align:top;"><img src="https://orcid.org/sites/default/files/images/orcid_16x16.png" style="width:1em;margin-right:.5em;" alt="ORCID iD icon">https://orcid.org/0000-0002-5445-4417</a></div>
